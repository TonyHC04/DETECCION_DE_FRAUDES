{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b635d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Módulos cargados exitosamente.\n",
      "Datos cargados. Tamaño inicial: (5000, 5)\n",
      "Distribución inicial de Fraude (y): \n",
      "is_fraud\n",
      "0    4912\n",
      "1      88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- INICIANDO ANÁLISIS DE GRAFOS (Monitoreo Continuo AML) ---\n",
      "Grafo construido con 899 nodos y 4989 aristas.\n",
      "Feature de PageRank calculada y añadida a X.\n",
      "\n",
      "--- APLICANDO SMOTE PARA BALANCEO DE CLASES ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_17476\\3593040448.py:61: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['pagerank_score'].fillna(X['pagerank_score'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución después de SMOTE: \n",
      "is_fraud\n",
      "1    4912\n",
      "0    4912\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [23:34:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- REPORTE DE CLASIFICACIÓN (Métricas ML) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1000\n",
      "           1       1.00      0.99      0.99       965\n",
      "\n",
      "    accuracy                           0.99      1965\n",
      "   macro avg       0.99      0.99      0.99      1965\n",
      "weighted avg       0.99      0.99      0.99      1965\n",
      "\n",
      "\n",
      "✅ Proceso de entrenamiento COMPLETADO.\n",
      "Modelo guardado en: ../model_artifacts/xgboost_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# TITULO: 2. SETUP DE ENTRENAMIENTO Y FEATURE ENGINEERING (ATHOS)\n",
    "# UCAS: Aprendizaje de Máquinas, Minería de Datos (Grafos)\n",
    "# OBJETIVO: Entrenar el modelo XGBoost con features de riesgo PageRank\n",
    "# =================================================================\n",
    "\n",
    "## 1. Importación de Módulos Esenciales\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- CORRECCIÓN DE IMPORTACIÓN ---\n",
    "# Si ejecutas el Notebook desde 'notebooks/', solo necesitamos asegurar la ruta 'src'\n",
    "import sys\n",
    "import os\n",
    "# Añadir la carpeta raíz del proyecto al path (un nivel arriba)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir))) \n",
    "\n",
    "# Ahora importamos usando la estructura de carpetas: src.nombre_archivo\n",
    "from src.data_pipeline import simulate_historical_data\n",
    "from src.ml_features import build_transaction_graph, calculate_pagerank_feature\n",
    "# ----------------------------------\n",
    "\n",
    "print(\"✅ Módulos cargados exitosamente.\")\n",
    "\n",
    "## 2. Carga y Preparación de Datos (Fase Big Data)\n",
    "\n",
    "# Cargar el DataFrame base de transacciones\n",
    "df = simulate_historical_data()\n",
    "print(f\"Datos cargados. Tamaño inicial: {df.shape}\")\n",
    "print(f\"Distribución inicial de Fraude (y): \\n{df['is_fraud'].value_counts()}\")\n",
    "\n",
    "# Separar Features (X) y Target (y)\n",
    "X = df.drop('is_fraud', axis=1)\n",
    "y = df['is_fraud']\n",
    "# Eliminamos IDs que no son features de ML directo\n",
    "X = X.drop(['transaction_id'], axis=1)\n",
    "\n",
    "## 3. Feature Engineering de Redes (Minería de Datos / Grafos)\n",
    "\n",
    "print(\"\\n--- INICIANDO ANÁLISIS DE GRAFOS (Monitoreo Continuo AML) ---\")\n",
    "\n",
    "# Tarea 1: Construir el Grafo de Transacciones\n",
    "G = build_transaction_graph(df)\n",
    "print(f\"Grafo construido con {G.number_of_nodes()} nodos y {G.number_of_edges()} aristas.\")\n",
    "\n",
    "# Tarea 2: Calcular el PageRank (Feature de Influencia de Nodos)\n",
    "# PageRank es la Feature clave de Minería de Datos para el ML.\n",
    "df_pagerank = calculate_pagerank_feature(G)\n",
    "df_pagerank.rename(columns={'customer_id': 'sender_id'}, inplace=True) # Renombrar para unir\n",
    "\n",
    "# Unir la nueva feature al DataFrame principal (X)\n",
    "X = pd.merge(X, df_pagerank, on='sender_id', how='left')\n",
    "\n",
    "# Imputar valores nulos (cuentas sin PageRank, ej. nuevas cuentas)\n",
    "X['pagerank_score'].fillna(X['pagerank_score'].mean(), inplace=True)\n",
    "\n",
    "# Finalizar la preparación de X para el ML\n",
    "X = pd.get_dummies(X, columns=['sender_id', 'receiver_id'])\n",
    "\n",
    "print(\"Feature de PageRank calculada y añadida a X.\")\n",
    "\n",
    "## 4. Balanceo de Clases (Aprendizaje de Máquinas - SMOTE)\n",
    "\n",
    "# Esto es CRÍTICO para reducir Falsos Negativos (fraudes no detectados)\n",
    "print(\"\\n--- APLICANDO SMOTE PARA BALANCEO DE CLASES ---\")\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "print(f\"Distribución después de SMOTE: \\n{y_res.value_counts()}\")\n",
    "\n",
    "## 5. Entrenamiento y Evaluación del Modelo XGBoost\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar XGBoost (Modelo robusto requerido)\n",
    "model = XGBClassifier(n_estimators=100, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación de rendimiento\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\n--- REPORTE DE CLASIFICACIÓN (Métricas ML) ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Almacenar los datos de prueba y las probabilidades para el Demo Interactivo\n",
    "# Guardamos los datos originales de prueba para la simulación de Falsos Positivos\n",
    "X_test_orig = X[X.index.isin(y_test.index)] \n",
    "y_proba = model.predict_proba(X_test_orig)[:, 1] # Probabilidades de fraude\n",
    "\n",
    "## 6. Guardar Modelo y Datos de Prueba (Conexión al Demo Interactivo)\n",
    "\n",
    "# Exportar el modelo y los datos necesarios para el demo interactivo\n",
    "MODEL_FILE = '../model_artifacts/xgboost_model.pkl'\n",
    "DATA_FILE = '../model_artifacts/demo_data.pkl'\n",
    "\n",
    "os.makedirs('../model_artifacts', exist_ok=True)\n",
    "\n",
    "joblib.dump(model, MODEL_FILE)\n",
    "joblib.dump({'X_test': X_test_orig, 'y_proba': y_proba}, DATA_FILE)\n",
    "\n",
    "print(f\"\\n✅ Proceso de entrenamiento COMPLETADO.\")\n",
    "print(f\"Modelo guardado en: {MODEL_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c233b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
